#!/usr/bin/env bash
#####
# Run Solr related tasks (index, get status information, purge a collection)
#
#

. ./common-variables
PORT=8983

. ./solr-functions

ME=$(basename $0)

show_usage() { # display help message
  cat <<EOF
usage:
 ${ME} [-b|--db] [-p|--file-path] [-m|--file-mask] [-w|--no-delete]
       [-s|--solrFieldType] [-x|--marcxml] [-a|--alephseq] [-r|--trimId]
       [-d|--defaultRecordType] [-v|--marcVersion]
       [-A|--alephseqLineType] [-B|--validationCore] [-C|--outputDir]
       [-C|--indexWithTokenizedField]
       [-p|--purge] [-s|--status] [-h|--help]

 -b, --db <name>        name of the database
 -p, --file-path <path> the directory of the input files
 -m, --file-mask <mask> file mask (e.g. *.mrc)
 -w, --no-delete        do not delete the old index
 -s, --solrFieldType <field type>: How Solr field should be named.
                        Possible values: 'marc-tags', 'human-readable', or 'mixed'
 -l, --limit <limit>    index only a limited number of records
 -x, --marcxml          the source is in MARCXML format
 -a, --alephseq         the source is in Alephseq format
 -r, --trimId           trim record identifiers
 -d, --defaultRecordType <record type> the default record type if the record's type is undetectable.
                        Possible values: BOOKS (default), CONTINUING_RESOURCES, MUSIC, MAPS,
                        VISUAL_MATERIALS, COMPUTER_FILES, MIXED_MATERIALS
 -v, --marcVersion <version> MARC version.
                        Possible values: MARC21 (default), OCLC, DNB, GENT, SZTE, FENNICA, UNIMARC
 -i, --ignorableRecords <condition> ignore records from the analysis
 -g, --defaultEncoding  Default character encoding
 -A, --alephseqLineType The Aleph Seq line type: WITH_L, WITHOUT_L
 -F, --schemaType       metadata schema type ('MARC21', 'UNIMARC', or 'PICA')
 -f, --marcFormat       MARC format (like 'ISO' or 'MARCXML')
 -z, --ignorableFields  ignore fields from the analysis
 -J, --groupBy          group the results by the value of this data element (e.g. the ILN of  library)
 -B, --validationCore   the Solr collection used in the validation task
 -t, --outputDir        the directory to write the file listing the parameters
 -C, --indexWithTokenizedField
 -s, --status           status information
 -p, --purge            delete all records from a core
 -h, --help             this help
EOF
  exit 1
}

if [ $# -eq 0 ]; then
  show_usage
fi

GETOPT=$(getopt -o b:p:m:ws::xard:hSpv:l:i:g:A:F:f:z:J:B:t:C: \
  --long db:,file-path:,file-mask:,no-delete,solrFieldType:,marcxml,alephseq,trimId,defaultRecordType,help,status,purge,marcVersion:,limit:,ignorableRecords:,defaultEncoding:,alephseqLineType:,schemaType:,marcFormat:,ignorableFields:,groupBy:,validationCore:,outputDir:,outputDir,indexWithTokenizedField \
  -n ${ME} -- "$@")
eval set -- "$GETOPT"

DB=""
solrFieldType=mixed
defaultRecordType=BOOKS
marcVersion=MARC21
limit=""
DELETE=1
ignorableRecords=""
marcxml=""
alephseq=""
trimId=""
defaultEncoding=""
alephseqLineType=""
schemaType=""
marcFormat=""
ignorableFields=""
groupBy=""
validationCore=""
outputDir=""
indexWithTokenizedField=""
while true ; do
  case "$1" in
    -b|--db) DB=$2 ; shift 2;;
    -p|--file-path) FILE_PATH=$2 ; shift 2;;
    -m|--file-mask) FILE_MASK=$2 ; shift 2;;
    -w|--no-delete) DELETE=0 ; shift;;
    -s|--solrFieldType) solrFieldType=$2 ; shift 2;;
    -r|--defaultRecordType) defaultRecordType=$2 ; shift 2;;
    -v|--marcVersion) marcVersion=$2 ; shift 2;;
    -l|--limit) limit="--limit $2"; shift 2;;
    -i|--ignorableRecords) ignorableRecords="--ignorableRecords $2"; shift 2;;
    -x|--marcxml) marcxml="--marcxml" ; shift;;
    -a|--alephseq) alephseq="--alephseq" ; shift;;
    -r|--trimId) trimId="--trimId" ; shift;;
    -d|--defaultEncoding) defaultEncoding="--defaultEncoding $2" ; shift 2;;
    -A|--alephseqLineType) alephseqLineType="--alephseqLineType $2" ; shift 2;;
    -F|--schemaType) schemaType="--schemaType $2" ; shift 2;;
    -f|--marcFormat) marcFormat="--marcFormat $2" ; shift 2;;
    -z|--ignorableFields) ignorableFields="--ignorableFields $2" ; shift 2;;
    -J|--groupBy) groupBy="--groupBy $2" ; shift 2;;
    -B|--validationCore) validationCore=$2 ; shift 2;;
    -t|--outputDir) outputDir="--outputDir $2" ; shift 2;;
    -C|--indexWithTokenizedField) indexWithTokenizedField="--indexWithTokenizedField" ; shift ;;
    -S|--status) status ; shift ;;
    -p|--purge) purge_and_exit $DB ; shift ;;
    -h|--help) show_usage ; shift ;;
    --) shift ; break ;;
    *) echo "Internal error!: $1" ; exit 1 ;;
  esac
done

# echo "limit: $limit"
# echo "defaultEncoding: $defaultEncoding"

CORE=${DB}_dev

SOLR_DB_URL="${SOLR_HOST}/solr/${CORE}"

if [[ "${validationCore}" != "" ]]; then
  VALIDATION_PARAMS="--validationUrl ${SOLR_HOST}/solr/${validationCore}"
else
  VALIDATION_PARAMS=""
fi

echo "SOLR URL: $SOLR_DB_URL"

if [ "${DELETE}" == "1" ]; then
  purge_core $CORE
  # echo "Delete records in ${CORE}"
  # curl $SOLR_DB_URL/update -H "Content-type: text/xml" --data-binary '<delete><query>*:*</query></delete>'
fi

echo "Prepare schema"
prepare_schema $CORE

echo "Start indexing"
curl -s $SOLR_DB_URL/update -H "Content-type: text/xml" --data-binary '<commit/>'

cat <<EOT
running the command
---BEGIN
/usr/bin/java -cp $JAR de.gwdg.metadataqa.marc.cli.MarcToSolr \
  --solrUrl ${SOLR_DB_URL} \
  --solrFieldType $solrFieldType \
  --defaultRecordType $defaultRecordType \
  --marcVersion $marcVersion \
  ${VALIDATION_PARAMS} \
  $limit \
  $trimId \
  $marcxml \
  $alephseq \
  $ignorableRecords \
  $defaultEncoding \
  $alephseqLineType \
  $schemaType \
  $marcFormat \
  $ignorableFields \
  $groupBy \
  $outputDir \
  $indexWithTokenizedField \
  ${FILE_PATH}/${FILE_MASK}
---END
EOT

/usr/bin/java -cp $JAR de.gwdg.metadataqa.marc.cli.MarcToSolr \
  --solrUrl ${SOLR_DB_URL} --solrFieldType $solrFieldType \
  --defaultRecordType $defaultRecordType \
  --marcVersion $marcVersion \
  ${VALIDATION_PARAMS} \
  $limit $trimId $marcxml $alephseq $ignorableRecords $defaultEncoding $alephseqLineType $schemaType \
  $marcFormat $ignorableFields $groupBy $outputDir $indexWithTokenizedField \
  ${FILE_PATH}/${FILE_MASK}

# echo "Start optimizing"
# curl "$SOLR_DB_URL/update?optimize=true" -H 'Content-type: text/xml' --data-binary '<commit/>'
optimize_core $CORE

# dev -> production
echo "Swap ${CORE} to ${DB}"
swap_cores ${CORE} ${DB}

echo "indexing DONE"
